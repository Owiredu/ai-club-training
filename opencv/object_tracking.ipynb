{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OBJECT DETECTION AND TRACKING WITH YOLOv5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the necessary libraries\n",
    "import sys\n",
    "!{sys.executable} -m pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu116\n",
    "!{sys.executable} -m pip install pandas pyyaml tqdm seaborn numpy matplotlib opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clone the YOLOv5 repo\n",
    "!git clone https://github.com/ultralytics/yolov5  # clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import cv2\n",
    "import torch\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model (reference: https://github.com/ultralytics/yolov5)\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')  # or yolov5n - yolov5x6, custom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WITH IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get image\n",
    "img = cv2.imread('images/img-4.jpg')  # or file, Path, PIL, OpenCV, numpy, list\n",
    "# make inference\n",
    "results = model(img)\n",
    "# get the results as a pandas dataframe\n",
    "result_df = results.pandas().xyxy[0]\n",
    "\n",
    "# filter out object detections\n",
    "# supported objects:\n",
    "# - person\n",
    "# - bird, cat, cow, dog, horse, sheep\n",
    "# - aeroplane, bicycle, boat, bus, car, motorbike, train\n",
    "# - bottle, chair, dining table, potted plant, sofa, tv/monitor\n",
    "objects = result_df\n",
    "# objects = result_df[result_df[\"name\"] == \"person\"]\n",
    "\n",
    "# loop over the detections\n",
    "for i in range(objects.shape[0]):\n",
    "    # get a detected person detection data\n",
    "    object_row = objects.iloc[i]\n",
    "    start_x = int(object_row[\"xmin\"])\n",
    "    start_y = int(object_row[\"ymin\"])\n",
    "    end_x = int(object_row[\"xmax\"])\n",
    "    end_y = int(object_row[\"ymax\"])\n",
    "    confidence = round(object_row[\"confidence\"], 2) * 100\n",
    "    \n",
    "    # print object name, coords and confidence\n",
    "    print(f\"name: {object_row['name']} |\", f\"coords: {start_x, start_y, end_x, end_y}\", f\"| confidence: {confidence}%\")\n",
    "    \n",
    "    # fish out only results with confidence >= 50%\n",
    "    if object_row[\"confidence\"] >= 0.5:\n",
    "        # draw a rectangle\n",
    "        img = cv2.rectangle(\n",
    "            img=img.copy(), \n",
    "            pt1=(start_x, start_y), \n",
    "            pt2=(end_x, end_y), \n",
    "            color=(255, 0, 0), \n",
    "            thickness=3,\n",
    "            lineType=cv2.LINE_AA\n",
    "        )\n",
    "        \n",
    "        # write the name of the object on it's bounding box\n",
    "        # put text on the image\n",
    "        img = cv2.putText(\n",
    "            img=img.copy(), \n",
    "            text=f\"{object_row['name']} ({confidence}%)\", \n",
    "            org=(start_x, start_y), \n",
    "            fontFace=cv2.FONT_HERSHEY_COMPLEX, \n",
    "            fontScale=1, \n",
    "            color=(0, 255, 0), \n",
    "            thickness=3, \n",
    "            lineType=cv2.LINE_AA\n",
    "        )\n",
    "    \n",
    "# convert the image from BGR to RGB\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "# show resulting image\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WITH VIDEOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start video capture\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "# check whether the capture was opened successfully\n",
    "if not capture.isOpened():\n",
    "    print(\"Unable to start camera\")\n",
    "\n",
    "# initialize frame tracker and frame holders\n",
    "frames_tracker = 0\n",
    "previous_frame, current_frame, next_frame = None, None, None\n",
    "\n",
    "while True:\n",
    "    # capture the next frame\n",
    "    ret, frame = capture.read()\n",
    "    \n",
    "    # check whether the frame is available or not\n",
    "    if frame is None:\n",
    "        break\n",
    "    \n",
    "    ############################### BEGIN OBJECT DETECTION\n",
    "    \n",
    "    # make inference\n",
    "    results = model(frame)\n",
    "    # get the results as a pandas dataframe\n",
    "    result_df = results.pandas().xyxy[0]\n",
    "\n",
    "    # filter out object detections\n",
    "    # supported objects:\n",
    "    # - person\n",
    "    # - bird, cat, cow, dog, horse, sheep\n",
    "    # - aeroplane, bicycle, boat, bus, car, motorbike, train\n",
    "    # - bottle, chair, dining table, potted plant, sofa, tv/monitor\n",
    "    objects = result_df\n",
    "    # objects = result_df[result_df[\"name\"] == \"person\"]\n",
    "\n",
    "    # loop over the detections\n",
    "    for i in range(objects.shape[0]):\n",
    "        # get a detected person detection data\n",
    "        object_row = objects.iloc[i]\n",
    "        start_x = int(object_row[\"xmin\"])\n",
    "        start_y = int(object_row[\"ymin\"])\n",
    "        end_x = int(object_row[\"xmax\"])\n",
    "        end_y = int(object_row[\"ymax\"])\n",
    "        confidence = round(object_row[\"confidence\"], 2) * 100\n",
    "        \n",
    "        # fish out only results with confidence >= 50%\n",
    "        if object_row[\"confidence\"] >= 0.5:\n",
    "            # draw a rectangle\n",
    "            frame = cv2.rectangle(\n",
    "                img=frame.copy(), \n",
    "                pt1=(start_x, start_y), \n",
    "                pt2=(end_x, end_y), \n",
    "                color=(255, 0, 0), \n",
    "                thickness=3,\n",
    "                lineType=cv2.LINE_AA\n",
    "            )\n",
    "            \n",
    "            # write the name of the object on it's bounding box\n",
    "            # put text on the image\n",
    "            frame = cv2.putText(\n",
    "                img=frame.copy(), \n",
    "                text=f\"{object_row['name']} ({confidence}%)\", \n",
    "                org=(start_x, start_y), \n",
    "                fontFace=cv2.FONT_HERSHEY_COMPLEX, \n",
    "                fontScale=1, \n",
    "                color=(0, 255, 0), \n",
    "                thickness=3, \n",
    "                lineType=cv2.LINE_AA\n",
    "            )\n",
    "    \n",
    "    ############################### END OBJECT DETECTION\n",
    "    \n",
    "    # show the captured frame\n",
    "    cv2.imshow(\"Video\", frame)\n",
    "    \n",
    "    # wait 30 milliseconds for a key press event\n",
    "    keypressed = cv2.waitKey(30)\n",
    "    # if the ESC key is pressed, destroy all windows and release resources\n",
    "    if keypressed == 27:\n",
    "        # release camera\n",
    "        capture.release()\n",
    "        # destroy all windows\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d7c30d179e9c1a290940183286479ebb0e1ee6b9e15b239745f2952100a9585"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
